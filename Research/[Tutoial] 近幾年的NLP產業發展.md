# [Tutoial] 近幾年的NLP產業發展

- **Metadata** : `type: Tutoial` `scope: research` 
- **Techs Need** : `NLP`
- **Status**: `need-review`
<br/><br/>

## ✨ You should already know
- nothing

👩‍💻 👨‍💻

## ✨ About the wiki
- `Situation:` 對於剛入門或是非相關人士難以進入NLP領域。
- `Target:` 提供基本說明和文件方便對接。
- `Index:`

| Sub title | decription | memo |
| ------ | ------ | ------ |
| 基本定義 | 自然語言處理（NLP）是一門研究計算機如何理解、分析、操作和生成人類語言的學科 | - |
| 近些年NLP如何應用在教育場景 | 自然語言理解技術可以應用在教育場景中的例子 | - |
| 目前NLP的發展趨勢 | 目前更好地模擬人類的語言行為 | - |
| 參考文獻 | - | - |


---
<br>

### **概述**
> 介紹最近幾年的自然語言處理的產業發產

####  📝 基本定義
> 自然語言處理（NLP）是一門研究電腦機械應該如何理解、分析、操作和生成人類語言的學科。
> 它是人工智能（AI）的一個重要分支，也是許多AI技術的基礎。
> 近年來，自然語言處理技術在應用上取得了驚人的進展，各種模型推陳出新，特定任務上準確度也一直都在挑戰甚至超越人類。
> 而自然語言中最常見的處理方式有:
> 1. 深度學習模型框架：深度學習模型框架包括深度神經網絡（DNN）、長短期記憶（LSTM）、循環神經網絡（RNN）、注意力機制（Attention）等。
> 2. 詞嵌入模型框架：詞嵌入模型框架包括word2vec、GloVe、FastText等。
> 3. 語言模型框架：語言模型框架包括n-gram模型、隱馬爾可夫模型（HMM）、條件隨機場（CRF）等。
> 4. 自然語言處理模型框架：自然語言處理模型框架包括標註器（Tagger）、句法分析器（Parser）、語意分析器（Semantic Analyzer）等。
> 
>
> 而其中的深度模型框架更是當前著重發展目標，並這些模型從激烈的研究領域中脫穎而出：
> 1. BERT：BERT（Bidirectional Encoder Representations from Transformers）是Google AI研究小組開發的一種自然語言處理模型，它可以更好地理解自然語言，並提供更好的自然語言理解能力。
>          BERT可以用於詞性標註、句子分割、文本分類和其他自然語言任務。[1]
>
> 2. GPT：GPT（Generative Pre-trained Transformer）是OpenAI開發的一種自然語言生成模型，GPT是一種基於Transformer的架構和訓練程序，用於自然語言處理任務。
>         培訓遵循兩個階段的程序。首先，對未標記的數據使用語言建模目標來學習神經網絡模型的初始參數。
>         隨後，這些參數使用相應的監督目標適應目標任務。[2]
>
> 3. RoBERTa：RoBERTa（Robustly Optimized BERT Pretraining）是Facebook AI研究小組開發的一種自我監督模型(self-supervised)，根據BERT訓練不足的部分進行改良，並且可以達到或超過其後發布的每個模型的性能。
>             RoBERTa在 GLUE、RACE 和 SQuAD 上取得了最先進的結果，這些結果突出了以前被忽視的設計選擇的重要性。
>             RoBERTa使用深度學習技術，可以更好地理解自然語言，並提供更好的自然語言理解能力。[3]
> 透過這些框架，從聊天機器人到自然語言理解，從語音識別到語音合成，從文本分析到文本生成，都有了很大的突破。
>
>
> 自然語言處理技術的應用已經遍及各行各業，從金融、法律、醫療、教育、電子商務到搜索引擎，都有自然語言處理技術的蹤跡。
> 例如，金融行業可以利用自然語言處理技術來分析客戶的投資行為，以提供更好的投資建議；
> 法律行業可以利用自然語言處理技術來快速搜索法律文件，以提高工作效率；
> 醫療行業可以利用自然語言處理技術來自動識別病人的病史，以提高診斷的準確性；
> 電子商務行業可以利用自然語言處理技術來自動回答客戶的問題，以提高客戶服務水平；
> 搜索引擎行業可以利用自然語言處理技術來更好地理解用戶的查詢，以提高搜索結果的質量；
> 教育行業可以利用自然語言處理技術來協助教師快速同理學生的課程反饋，以提高教學效率。

####  📝 近些年NLP如何應用在教育場景
> 自然語言理解技術可以應用在教育場景中的方式有很多，例如：
1. 內容識別：可以用於評估教材與課程內容，以及針對不同需求提出輔助內容。
2. 自然語言處理：可以用於自動分析學生的作業，提供教師在批改作業時的評分參考。
3. 學習輔助：可以用於評估學生的對於課程的理解程度與學習表現，以及提供及時的反饋。
4. 智能助手：可以用於提供學生在學習過程中的指導和支持。
5. 聊天機器人：可以用於提供學生在學習過程中的指導和支持，以及提供一對一的建議評估。

####  📝 目前NLP的發展趨勢
> 目前NLP的發展趨勢越來越靠近人類的思維，越來越多的技術被開發出來，以更好地模擬人類的語言行為。
> 其中，自然語言處理技術的發展趨勢是深度學習，特別是深度神經網絡，它們可以更好地模擬人類的語言行為，並提供更好的結果。
> 此外，詞嵌入技術也被廣泛應用於NLP，它可以更好地表示詞語之間的關係，並提供更好的結果，常被應用於詞性標註，句法分析，語義分析等NLP任務。
> 當前NLP的訓練方式是以Pre-train mode搭配transfer learning為主，因為Pre-train model擁有大量的資料訓練出來的成果，透過transfer learning
> 可以讓不同的子任務的模型可以更快訓練出來，讓NLP技術可以更加普及，應用到更多的領域。

####  📝 參考文獻
1. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
2. Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.
3. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.
